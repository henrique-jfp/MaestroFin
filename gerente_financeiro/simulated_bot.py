import json
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

# --- InÃ­cio do PromptManager e PromptConfig (para ser autocontido) ---
# Em um projeto real, vocÃª importaria isso de 'prompt_manager.py'
@dataclass(frozen=True)
class PromptConfig:
    """ConfiguraÃ§Ãµes para a construÃ§Ã£o de um prompt dinÃ¢mico."""
    user_name: str
    user_query: str
    financial_context: Dict[str, Any]
    conversation_history: str = ""
    behavioral_analysis_json: Optional[Dict[str, Any]] = None
    intent: str = "general_analysis" 
    relevant_skills: Optional[List[str]] = None
    mes_nome: Optional[str] = None
    ano: Optional[int] = None
    receita_total: Optional[float] = None
    despesa_total: Optional[float] = None
    saldo_mes: Optional[float] = None
    taxa_poupanca: Optional[float] = None
    gastos_agrupados: Optional[str] = None

from jinja2 import Environment, FileSystemLoader, TemplateNotFound

class PromptManager:
    """
    Gerencia e constrÃ³i prompts dinamicamente a partir de templates modulares.
    """
    def __init__(self, template_dir: Path):
        if not template_dir.is_dir():
            raise FileNotFoundError(f"O diretÃ³rio de templates nÃ£o existe: {template_dir}")
        
        self.env = Environment(
            loader=FileSystemLoader(template_dir),
            trim_blocks=True,
            lstrip_blocks=True
        )

    def _load_template_content(self, template_path_str: str, **kwargs) -> str:
        """Carrega e renderiza o conteÃºdo de um template especÃ­fico."""
        try:
            template = self.env.get_template(template_path_str)
            return template.render(**kwargs)
        except TemplateNotFound:
            raise ValueError(f"Template nÃ£o encontrado: {template_path_str}. Verifique o caminho e o nome do arquivo.")
        except Exception as e:
            raise RuntimeError(f"Erro ao renderizar template {template_path_str}: {e}")

    def build_prompt(self, config: PromptConfig) -> str:
        """
        ConstrÃ³i o prompt final com base na configuraÃ§Ã£o e intenÃ§Ã£o.
        """
        if config.intent == "function_call":
            persona = self._load_template_content("system/persona_gerente_vdm.md", user_name=config.user_name, pergunta_usuario=config.user_query)
            function_rules = self._load_template_content("rules/function_calling.md")
            
            return self._load_template_content(
                "skills/function_call_query.j2",
                persona=persona,
                function_rules=function_rules,
                user_name=config.user_name,
                user_query=config.user_query
            )
        
        elif config.intent == "insight":
            return self._load_template_content(
                "templates/insight_final.j2",
                user_name=config.user_name,
                user_query=config.user_query
            )

        elif config.intent == "conversation":
            # Passa o dict para o Jinja
            return self._load_template_content(
                "templates/conversation_context.j2",
                user_name=config.user_name,
                conversation_history=config.conversation_history,
                user_query=config.user_query,
                financial_context=config.financial_context,
                behavioral_analysis_json=config.behavioral_analysis_json
            )
        
        elif config.intent == "monthly_report":
            required_fields = ["mes_nome", "ano", "receita_total", "despesa_total", "saldo_mes", "taxa_poupanca", "gastos_agrupados"]
            for field in required_fields:
                if getattr(config, field) is None:
                    raise ValueError(f"Campo '{field}' Ã© obrigatÃ³rio para a intenÃ§Ã£o 'monthly_report'.")

            return self._load_template_content(
                "templates/monthly_report_analysis.j2",
                user_name=config.user_name,
                mes_nome=config.mes_nome,
                ano=config.ano,
                receita_total=config.receita_total,
                despesa_total=config.despesa_total,
                saldo_mes=config.saldo_mes,
                taxa_poupanca=config.taxa_poupanca,
                gastos_agrupados=config.gastos_agrupados
            )

        elif config.intent == "general_analysis":
            persona = self._load_template_content("system/persona_gerente_vdm.md", user_name=config.user_name, pergunta_usuario=config.user_query)
            formatting_rules = self._load_template_content("rules/formatting_html.md")

            skills_content = ""
            if config.relevant_skills:
                for skill_name in config.relevant_skills:
                    skills_content += self._load_template_content(f"skills/{skill_name}.md") + '''\n\n'''
            
            if skills_content:
                skills_content = skills_content.strip()

            return self._load_template_content(
                "main_analysis.j2",
                persona=persona,
                formatting_rules=formatting_rules,
                skills=skills_content,
                user_name=config.user_name,
                user_query=config.user_query,
                financial_context=config.financial_context,
                conversation_history=config.conversation_history
            )
        else:
            raise ValueError(f"IntenÃ§Ã£o '{config.intent}' nÃ£o reconhecida pelo PromptManager.")
# --- Fim do PromptManager e PromptConfig ---


# --- ConfiguraÃ§Ã£o do PromptManager para o bot simulado ---
# Assume que o diretÃ³rio 'prompts' estÃ¡ no mesmo nÃ­vel do 'simulated_bot.py'
PROMPTS_DIR = Path(__file__).parent / "prompts"
prompt_manager = PromptManager(template_dir=PROMPTS_DIR)

# --- FunÃ§Ãµes de SimulaÃ§Ã£o para o Bot ---

def get_user_data(user_id: str, user_name: str) -> Dict[str, Any]:
    """
    Simula a obtenÃ§Ã£o de dados do usuÃ¡rio de um DB/estado.
    VocÃª substituirÃ¡ isso pela sua lÃ³gica real.
    """
    # Dados fictÃ­cios para demonstraÃ§Ã£o
    financial_context = {
        "user_id": user_id,
        "user_name": user_name,
        "accounts": [{"name": "Conta Corrente", "balance": 2500.0}],
        "transactions": [
            {"description": "Uber", "amount": 45.0, "category": "Transporte"},
            {"description": "Jantar", "amount": 120.0, "category": "AlimentaÃ§Ã£o"},
            {"description": "SalÃ¡rio", "amount": 3000.0, "category": "Receita"}
        ],
        "goals": [
            {"name": "Viagem Europa", "target": 10000.0, "current": 3500.0, "deadline": "2024-12-31"},
            {"name": "EmergÃªncia", "target": 5000.0, "current": 4800.0, "deadline": None}
        ],
    }
    conversation_history = "Na nossa Ãºltima conversa, vocÃª perguntou sobre seus gastos com delivery e sugeri reduzir em 10%."
    behavioral_analysis = {"tendencia_gastos": "aumento_lazer_recente", "economia_potencial_delivery": 150}

    return {
        "financial_context": financial_context,
        "conversation_history": conversation_history,
        "behavioral_analysis_json": behavioral_analysis,
    }

def determine_user_intent(user_query: str) -> Tuple[str, Optional[Any]]: # Optional[Any] para aceitar dict ou list
    """
    SIMULA a detecÃ§Ã£o da intenÃ§Ã£o do usuÃ¡rio.
    Em produÃ§Ã£o, isso seria um LLM menor, embeddings + classificador, ou regex mais robusto.
    Retorna a intenÃ§Ã£o e, opcionalmente, parÃ¢metros para function_call ou lista de skills para general_analysis.
    """
    query_lower = user_query.lower()

    if "Ãºltimo gasto" in query_lower or "listar" in query_lower or "detalhes" in query_lower or "transaÃ§Ã£o" in query_lower:
        # Exemplo de extraÃ§Ã£o de parÃ¢metros simples (vocÃª faria isso de forma mais robusta)
        params = {"limit": 1}
        if "lazer" in query_lower:
            params["categoria_nome"] = "Lazer"
        if "alimentaÃ§Ã£o" in query_lower:
            params["categoria_nome"] = "AlimentaÃ§Ã£o"
        if "uber" in query_lower:
            params["query"] = "Uber"
        if "2 gastos" in query_lower:
            params["limit"] = 2
        if "3 maiores gastos" in query_lower:
            params["limit"] = 3
            if "alimentaÃ§Ã£o" in query_lower:
                params["categoria_nome"] = "AlimentaÃ§Ã£o"
        return "function_call", params
    
    elif "insight" in query_lower or "dica" in query_lower or "recomendaÃ§" in query_lower or "economias" in query_lower:
        return "insight", None
    
    elif "relatÃ³rio mensal" in query_lower or "resumo do mÃªs" in query_lower or "gerar relatÃ³rio" in query_lower:
        return "monthly_report", None
    
    elif "compare" in query_lower or "comparar" in query_lower:
        return "general_analysis", ["comparative_analysis", "proactive_insights"]
    
    elif any(greeting in query_lower for greeting in ["oi", "olÃ¡", "e aÃ­", "bom dia", "boa tarde", "boa noite"]):
        return "conversation", None
    
    elif "meta de viagem" in query_lower or "minha meta" in query_lower:
         return "general_analysis", ["proactive_insights"] # Para monitorar e dar dicas sobre metas

    else:
        # IntenÃ§Ã£o padrÃ£o para anÃ¡lise geral com um conjunto de skills bÃ¡sicas
        return "general_analysis", [
            "strategic_questions",
            "proactive_insights",
            "payment_account_analysis",
            "lists_rankings",
            "period_summaries",
            "simple_predictive_analysis",
        ]

def call_llm_api_and_get_response(prompt: str, intent: str, additional_intent_data: Optional[Any]) -> str:
    """
    SIMULA a chamada Ã  API do seu LLM (e.g., Gemini, GPT-4).
    Em produÃ§Ã£o, vocÃª faria uma requisiÃ§Ã£o HTTP real aqui.
    """
    print(f"\n--- CHAMANDO O LLM COM ESTE PROMPT (Truncado para leitura, {len(prompt.split())} palavras) ---")
    print(prompt[:1000] + "\n... (fim do prompt)\n") # Imprime apenas o comeÃ§o para nÃ£o poluir

    # --- LÃ³gica de Resposta Simulada APRIMORADA ---
    if intent == "function_call":
        # Se a intenÃ§Ã£o Ã© function_call, o LLM deve retornar APENAS o JSON.
        # Simulamos que ele faria isso usando os additional_intent_data (os parÃ¢metros)
        func_name = "listar_lancamentos"
        params_str = json.dumps(additional_intent_data, indent=2)
        return f"DEBUG: LLM respondeu com JSON para {func_name}: {{ \"funcao\": \"{func_name}\", \"parametros\": {params_str} }}"

    # Respostas simuladas baseadas em palavras-chave no prompt (substitua pela lÃ³gica real do LLM)
    if "Ãºltimo gasto" in prompt.lower() or "listar lanÃ§amentos" in prompt.lower():
        return "DEBUG: Analisado pelo LLM: Seu Ãºltimo gasto foi <code>R$ 45,00</code> com <i>Uber</i> em <i>Transporte</i>. Que tal explorar alternativas de transporte mais econÃ´micas em dias especÃ­ficos? ğŸ’¡"
    elif "compare" in prompt.lower():
        return "DEBUG: Analisado pelo LLM: <b>ğŸ“Š Comparativo de Gastos (Q1 vs Q2)</b>\nâ€¢ Seus gastos em AlimentaÃ§Ã£o aumentaram <i>15%</i> no Q2, totalizando <code>R$ 1.200,00</code>. \nâ€¢ <b>ğŸ’¡ Insight:</b> Percebo que seus gastos com refeiÃ§Ãµes fora de casa foram o principal motor. Que tal planejar 2-3 refeiÃ§Ãµes caseiras por semana para economizar? ğŸ³"
    elif "insight" in prompt.lower():
        return "DEBUG: Analisado pelo LLM: ğŸ’¡ <b>Insights do Maestro</b>\nVocÃª tem uma excelente disciplina! Sua meta de <i>EmergÃªncia</i> estÃ¡ quase completa. Foco total na <i>Viagem Europa</i> agora! ğŸš€"
    elif "olÃ¡" in prompt.lower() or "tudo bem" in prompt.lower():
        return "DEBUG: Analisado pelo LLM: OlÃ¡! Que bom ter vocÃª por aqui. Estou pronto para te ajudar a conquistar seus objetivos financeiros. Como posso te auxiliar hoje? âœ¨"
    elif "relatÃ³rio mensal" in prompt.lower():
        return "DEBUG: Analisado pelo LLM: <b>ğŸ¯ Resumo de Novembro</b>\nâ€¢ Receitas: <code>R$ 4.500,00</code>\nâ€¢ Despesas: <code>R$ 3.000,00</code>\nâ€¢ Saldo: <code>R$ 1.500,00</code>\nâ€¢ <b>ğŸ’¡ Insight:</b> Sua taxa de poupanÃ§a de <i>33.3%</i> Ã© fantÃ¡stica! Continue monitorando os gastos com <i>Lazer</i> para manter o ritmo. ğŸ“ˆ"
    elif "meta de viagem" in prompt.lower():
        return "DEBUG: Analisado pelo LLM: Sua meta de <i>Viagem Europa</i> estÃ¡ em <code>35%</code>. Faltam <code>R$ 6.500,00</code>. Com o ritmo atual, vocÃª a alcanÃ§a em 7 meses. Quer uma dica para acelerar? âœˆï¸"
    elif "maiores gastos com alimentaÃ§Ã£o" in prompt.lower():
         return "DEBUG: Analisado pelo LLM: Seus 3 maiores gastos com <i>AlimentaÃ§Ã£o</i> foram: \nâ€¢ Restaurante X (<code>R$ 80,00</code>)\nâ€¢ Supermercado Y (<code>R$ 75,00</code>)\nâ€¢ Delivery Z (<code>R$ 60,00</code>)\n Considere cozinhar mais em casa para otimizar. ğŸ›’"
    
    return "DEBUG: Analisado pelo LLM: Sua pergunta foi processada. Estou sempre aprendendo para te dar as melhores informaÃ§Ãµes financeiras! ğŸ¤”"


# --- FunÃ§Ã£o Principal de Processamento de Mensagem do Bot Unificada ---

def process_user_message_unified(user_id: str, user_name: str, user_query: str) -> str:
    """
    Processa a mensagem do usuÃ¡rio de ponta a ponta:
    1. ObtÃ©m dados do usuÃ¡rio (simulado).
    2. Determina a intenÃ§Ã£o do usuÃ¡rio (simulado).
    3. ConstrÃ³i o PromptConfig.
    4. Gera o prompt otimizado usando o PromptManager.
    5. Chama a API do LLM (simulado).
    6. Retorna a resposta final.
    """
    print(f"\n{'='*20} NOVO PEDIDO {'='*20}")
    print(f">>> Processando mensagem de {user_name} (ID: {user_id}): '{user_query}' <<<")

    # 1. Obter dados relevantes do usuÃ¡rio (substitua pela sua lÃ³gica real de DB/estado)
    user_data = get_user_data(user_id, user_name)
    financial_context = user_data["financial_context"]
    conversation_history = user_data["conversation_history"]
    behavioral_analysis_json = user_data["behavioral_analysis_json"]

    # 2. Determinar a intenÃ§Ã£o do usuÃ¡rio (substitua pela sua lÃ³gica real)
    # determine_user_intent retorna (intent_str, optional_params_or_skills_list)
    intent, additional_intent_data = determine_user_intent(user_query)
    
    print(f"IntenÃ§Ã£o detectada: '{intent}'. Dados adicionais: {additional_intent_data}")

    # 3. Preparar a configuraÃ§Ã£o do prompt
    prompt_config_kwargs = {
        "user_name": user_name,
        "user_query": user_query,
        "financial_context": financial_context,
        "conversation_history": conversation_history,
        "behavioral_analysis_json": behavioral_analysis_json,
        "intent": intent,
    }

    # Adiciona dados especÃ­ficos dependendo da intenÃ§Ã£o
    if intent == "general_analysis":
        prompt_config_kwargs["relevant_skills"] = additional_intent_data # additional_intent_data Ã© a lista de skills
    elif intent == "monthly_report":
        # Em um cenÃ¡rio real, vocÃª buscaria ou calcularia os dados reais do relatÃ³rio mensal aqui
        monthly_report_params = {
            "mes_nome": "Novembro",
            "ano": 2023,
            "receita_total": 4500.0,
            "despesa_total": 3000.0,
            "saldo_mes": 1500.0,
            "taxa_poupanca": 33.3,
            "gastos_agrupados": "AlimentaÃ§Ã£o (R$ 900), Lazer (R$ 600)"
        }
        prompt_config_kwargs.update(monthly_report_params)


    prompt_config = PromptConfig(**prompt_config_kwargs)

    # 4. Construir o prompt dinamicamente
    final_prompt = prompt_manager.build_prompt(prompt_config)

    # 5. Chamar o LLM com o prompt gerado e obter a resposta simulada
    llm_response = call_llm_api_and_get_response(final_prompt, intent, additional_intent_data)

    return llm_response

# --- ExecuÃ§Ã£o de Exemplo para Testar o Bot Simulado ---
if __name__ == "__main__":
    print(f"\n{'#'*80}")
    print(f"{'#'*8} DEMONSTRAÃ‡ÃƒO DO BOT SIMULADO COM NOVO SISTEMA DE PROMPTS {'#'*8}")
    print(f"{'#'*80}\n")

    # Testes com diferentes tipos de mensagens
    test_cases = [
        ("user_001", "Alice", "Me mostre meu Ãºltimo gasto."),
        ("user_002", "Bruno", "Quais foram meus Ãºltimos 2 gastos com lazer?"), 
        ("user_003", "CecÃ­lia", "Me dÃª um insight sobre minhas economias."),
        ("user_004", "Daniel", "OlÃ¡ ContaComigo, tudo bem?"),
        ("user_005", "Elaine", "Gere o relatÃ³rio mensal de Novembro."),
        ("user_006", "FÃ¡bio", "Compare meus gastos de janeiro e fevereiro com transporte."),
        ("user_007", "Gustavo", "Como estÃ¡ minha meta de viagem?"),
        ("user_008", "Helena", "Liste meus 3 maiores gastos com alimentaÃ§Ã£o."),
        ("user_009", "Ivo", "NÃ£o entendi bem o balanÃ§o do mÃªs passado. Pode explicar?"), 
    ]

    for user_id, user_name, user_query in test_cases:
        response = process_user_message_unified(user_id, user_name, user_query)
        print(f"\n{'='*5} RESPOSTA FINAL DO BOT PARA '{user_query}' {'='*5}\n{response}\n")
        print(f"{'='*60}\n")
